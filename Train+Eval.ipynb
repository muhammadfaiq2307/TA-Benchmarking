{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5cefac89"
      },
      "source": [
        "# Fine-tune Whisper (large) with LoRA & BNB powerd by PEFT ⚡️"
      ],
      "id": "5cefac89"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "090fa3ed"
      },
      "source": [
        "A one size fits all notebook, to fine-tune Whisper (large) on a consumer GPU with less than 8GB GPU VRAM, all with comparable performance to full-finetuning. ⚡️\n",
        "\n",
        "We present a step-by-step guide on how to fine-tune Whisper with Common Voice 13.0 dataset using 🤗 Transformers and PEFT. In this Colab, we leverage `PEFT` and `bitsandbytes` to train a `whisper-large-v2` checkpoint seamlessly with a free T4 GPU (16 GB VRAM).\n",
        "\n",
        "For more details on Whisper fine-tuning, datasets and metrics, refer to Sanchit Gandhi's brilliant blogpost: [Fine-Tune Whisper For Multilingual ASR with 🤗 Transformers](https://huggingface.co/blog/fine-tune-whisper)\n",
        "\n",
        "## Why Parameter Efficient Fine Tuning ([PEFT](https://github.com/huggingface/peft))?\n",
        "\n",
        "As the model size continue to increase, fine tuning a model has become both computationally expensive and storage heavy. For example, a `Whisper-large-v2` model requires ~24GB of GPU VRAM to fine-tune for full fine-tuning and requires ~7 GB of storage for each fine-tuned storage. For low-resource environments this becomes quite a bottleneck and often near impossible to get meaningful results.\n",
        "\n",
        "Cue, PEFT, with PEFT you can tackle this bottleneck head on. PEFT approaches (like Low Rank Adaptation) only fine-tune a small number of (extra) model parameters while freezing most parameters of the pretrained model, thereby greatly decreasing the computational and storage costs. We've observed that it also overcomes the issues of catastrophic forgetting, a behaviour observed during the full finetuning of large models.\n",
        "\n",
        "### Aha! So wait, what's this LoRA thing?\n",
        "\n",
        "PEFT comes out-of-the-box with multiple parameter efficient techniques. One such technique is [Low Rank Adaptation or LoRA](https://github.com/microsoft/LoRA). LoRA freezes the pre-trained model weights and injects trainable rank decomposition matrices into each layer of the Transformer architecture. This greatly reduces the number of trainable parameters for downstream tasks.\n",
        "\n",
        "LoRA performs on-par or better than fine-tuning in model quality despite having fewer trainable parameters, a higher training throughput, and, unlike adapters, no additional inference latency.\n",
        "\n",
        "### That's all cool, but show me the numbers?\n",
        "\n",
        "Don't worry, we got ya! We ran multiple experiments to compare a full fine-tuning of Whisper-large-v2 checkpoint and that with PEFT, here's what we found:\n",
        "\n",
        "1. We were able to fine-tune a 1.6B parameter model with less than 8GB GPU VRAM. 🤯\n",
        "2. With significantly less number of traininable parameters, we were able to fit almost **5x** more batch size. 📈\n",
        "3. The resultant checkpoint were less than 1% the size of the original model, ~60MB (i.e. 1% the size of orignal model) 🚀\n",
        "\n",
        "To make things even better, all of this comes with minimal changes to the existing 🤗 transformers Whisper inference codebase.\n",
        "\n",
        "### Curious to test this out for yourself? Follow along!"
      ],
      "id": "090fa3ed"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "625e47a0"
      },
      "source": [
        "## Prepare Environment\n",
        "\n",
        "We'll employ several popular Python packages to fine-tune the Whisper model.\n",
        "We'll use `datasets` to download and prepare our training data and\n",
        "`transformers` to load and train our Whisper model. We'll also require\n",
        "the `librosa` package to pre-process audio files, `evaluate` and `jiwer` to\n",
        "assess the performance of our model. Finally, we'll\n",
        "use `PEFT`, `bitsandbytes`, `accelerate` to prepare and fine-tune the model with LoRA."
      ],
      "id": "625e47a0"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r_Ivl7qlX0dz",
        "outputId": "7111a289-ca30-4bda-aee9-1a138def351a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m72.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m486.2/486.2 kB\u001b[0m \u001b[31m44.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.4/81.4 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m70.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.1/97.1 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.6/227.6 kB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.8/236.8 kB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m75.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m110.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.3/134.3 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m69.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.5/212.5 kB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m81.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.4/75.4 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.4/288.4 kB\u001b[0m \u001b[31m33.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.0/137.0 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.5/50.5 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.0/57.0 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "#pip install -q transformers datasets librosa evaluate jiwer gradio bitsandbytes==0.37 accelerate\n",
        "!pip install -q transformers datasets librosa evaluate jiwer gradio bitsandbytes accelerate\n",
        "#!pip install -q git+https://github.com/huggingface/peft.git@main"
      ],
      "id": "r_Ivl7qlX0dz"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q peft==0.2.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AYb2-9HmNSFp",
        "outputId": "685e7dbf-fe4e-45cf-9db5-ee1c1a20da05"
      },
      "id": "AYb2-9HmNSFp",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/40.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.3/40.3 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2MvOaXjUjK71"
      },
      "source": [
        "With the environment now set up, let's try to secure a decent GPU for our Colab! Unfortunately, it's becoming much harder to get access to a good GPU with the free version of Google Colab. However, with Google Colab Pro one should have no issues in being allocated a V100 or P100 GPU.\n",
        "\n",
        "To get a GPU, click _Runtime_ -> _Change runtime type_, then change _Hardware accelerator_ from _None_ to _GPU_.\n",
        "\n",
        "We can verify that we've been assigned a GPU and view its specifications:"
      ],
      "id": "2MvOaXjUjK71"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2kBtM9XSjKE5",
        "outputId": "01adae55-e9c5-4c0f-b6fb-a9fd0e5cc54f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Jun 24 07:24:21 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   32C    P0    23W / 300W |      0MiB / 16384MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "id": "2kBtM9XSjKE5"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6WwnavbBuezQ"
      },
      "source": [
        "Alrighty! Let's configure our environment to ensure it uses the GPU provided by Colab to us."
      ],
      "id": "6WwnavbBuezQ"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "e1da5fff"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
      ],
      "id": "e1da5fff"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8a528c1a"
      },
      "source": [
        "We strongly advise you to upload model checkpoints directly the [Hugging Face Hub](https://huggingface.co/)\n",
        "whilst training. The Hub provides:\n",
        "- Integrated version control: you can be sure that no model checkpoint is lost during training.\n",
        "- Tensorboard logs: track important metrics over the course of training.\n",
        "- Model cards: document what a model does and its intended use cases.\n",
        "- Community: an easy way to share and collaborate with the community!\n",
        "\n",
        "Linking the notebook to the Hub is straightforward - it simply requires entering your Hub authentication token when prompted. Find your Hub authentication token [here](https://huggingface.co/settings/tokens):"
      ],
      "id": "8a528c1a"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "816d8f0ad9e24a319ed2bf9d631fbdbb",
            "4d7b760327d14326acc69f51baa19856",
            "e424996b5fc34fd5809fddd0250492e1",
            "9e8c038169cf47288a0da9f50e1d1b48",
            "47d97646ec8e404facaf49e8e06852e1",
            "3c2f06b6024045dcaded354b23c5cf02",
            "5e3dd987a32f40fba73751e0546e9cb2",
            "9adfdcad8feb4f4daddc0ff0a8ac5934",
            "3f1f3b36d6c74fd58e0f844c38a01ca1",
            "21bc8e541e22444c86f98948fcbfa001",
            "7ed3852664ea4964b189bc1ba424ad3a",
            "1741456fec04410192cdc333ea980158",
            "fb6234984b10494ca95c5f2764dcec12",
            "7b9fdc420cb9450e9db0e787b532fae4",
            "b4c4867224f94fa0bf9f6a8f1a75dc6a",
            "6045c0dbdd2c45cea65e1227cbb00039",
            "33c1013250dd4ea3b2af3663eba6ae75",
            "292f6f3b4d0f4f249777e14d6ceea99d",
            "5fcc534556fb4b158e7ac12c5d1b7112",
            "94d35dc19f6441d4978235901c76cadd",
            "22fd3006e67447d08c3a0357cce6a097",
            "dd4c9944d49c466cb429a60f1637b415",
            "956683b15f534dac87e967ea4d2e150e",
            "56c15eca011b40bda614f216d9d39178",
            "e6147ce00db94d20b0a422cbc53db128",
            "de58f41f178b4eabbf65210503163cc4",
            "e58dd3f4b13a47eda8f85d35b362e299",
            "9328578d5e534286ac61a3ae53ea3400",
            "15865653f578497ea05cf0ddeb2f79ef",
            "a766499eb4eb4e60903acafc2251b159",
            "ababb664997946bfa11026bc59a3c815",
            "e4410ca791c8427f97b5414acb150d08"
          ]
        },
        "id": "ed0OpduhX2JF",
        "outputId": "c20c3db8-a164-4628-fa38-d72905b1fad9"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "816d8f0ad9e24a319ed2bf9d631fbdbb"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ],
      "id": "ed0OpduhX2JF"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gG-2lYDPw3uW"
      },
      "source": [
        "Next up, we define Whisper model checkpoints and task details."
      ],
      "id": "gG-2lYDPw3uW"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "mJ9M1WKhu0KM"
      },
      "outputs": [],
      "source": [
        "model_name_or_path = \"openai/whisper-large-v2\"\n",
        "task = \"transcribe\""
      ],
      "id": "mJ9M1WKhu0KM"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EuhppXc9xAt2"
      },
      "source": [
        "Lastly, we define the dataset details, including the language we'd like to fine-tune Whisper on too."
      ],
      "id": "EuhppXc9xAt2"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "7sE0FPf7w-he"
      },
      "outputs": [],
      "source": [
        "dataset_name = \"mozilla-foundation/common_voice_13_0\"\n",
        "language = \"Indonesian\"\n",
        "language_abbr = \"id\" # Short hand code for the language we want to fine-tune"
      ],
      "id": "7sE0FPf7w-he"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XPI5OZz4u3b1"
      },
      "source": [
        "# Load Dataset\n",
        "\n",
        "Using 🤗 Datasets, downloading and preparing data is extremely simple.\n",
        "We can download and prepare the Common Voice splits in just one line of code.\n",
        "\n",
        "First, ensure you have accepted the terms of use on the Hugging Face Hub: [mozilla-foundation/common_voice_13_0](https://huggingface.co/datasets/mozilla-foundation/common_voice_13_0). Once you have accepted the terms, you will have full access to the dataset and be able to download the data locally.\n",
        "\n",
        "Since Hindi is very low-resource, we'll combine the `train` and `validation`\n",
        "splits to give approximately 12 hours of training data. We'll use the 6 hours\n",
        "of `test` data as our held-out test set:"
      ],
      "id": "XPI5OZz4u3b1"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a2787582-554f-44ce-9f38-4180a5ed6b44",
        "outputId": "d269248d-7cb3-4974-a266-f831bea80224"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.builder:Found cached dataset common_voice_13_0 (/root/.cache/huggingface/datasets/mozilla-foundation___common_voice_13_0/id/13.0.0/22809012aac1fc9803eaffc44122e4149043748e93933935d5ea19898587e4d7)\n",
            "WARNING:datasets.builder:Found cached dataset common_voice_13_0 (/root/.cache/huggingface/datasets/mozilla-foundation___common_voice_13_0/id/13.0.0/22809012aac1fc9803eaffc44122e4149043748e93933935d5ea19898587e4d7)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['client_id', 'path', 'audio', 'sentence', 'up_votes', 'down_votes', 'age', 'gender', 'accent', 'locale', 'segment', 'variant'],\n",
            "        num_rows: 8333\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['client_id', 'path', 'audio', 'sentence', 'up_votes', 'down_votes', 'age', 'gender', 'accent', 'locale', 'segment', 'variant'],\n",
            "        num_rows: 3649\n",
            "    })\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset, DatasetDict\n",
        "\n",
        "common_voice = DatasetDict()\n",
        "\n",
        "common_voice[\"train\"] = load_dataset(dataset_name, language_abbr, split=\"train+validation\", use_auth_token=True)\n",
        "common_voice[\"test\"] = load_dataset(dataset_name, language_abbr, split=\"test\", use_auth_token=True)\n",
        "\n",
        "print(common_voice)"
      ],
      "id": "a2787582-554f-44ce-9f38-4180a5ed6b44"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "805b1c56"
      },
      "source": [
        "Most ASR datasets only provide input audio samples (`audio`) and the\n",
        "corresponding transcribed text (`sentence`). Common Voice contains additional\n",
        "metadata information, such as `accent` and `locale`, which we can disregard for ASR.\n",
        "Keeping the notebook as general as possible, we only consider the input audio and\n",
        "transcribed text for fine-tuning, discarding the additional metadata information:"
      ],
      "id": "805b1c56"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "20ba635d-518c-47ac-97ee-3cad25f1e0ce",
        "outputId": "079864cb-30ee-4d11-aa1d-99df6ffb1cca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['audio', 'sentence'],\n",
            "        num_rows: 8333\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['audio', 'sentence'],\n",
            "        num_rows: 3649\n",
            "    })\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "common_voice = common_voice.remove_columns(\n",
        "    [\"accent\", \"age\", \"client_id\", \"down_votes\", \"gender\", \"locale\", \"path\", \"segment\", \"up_votes\", \"variant\"]\n",
        ")\n",
        "\n",
        "print(common_voice)"
      ],
      "id": "20ba635d-518c-47ac-97ee-3cad25f1e0ce"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2d63b2d2-f68a-4d74-b7f1-5127f6d16605"
      },
      "source": [
        "## Prepare Feature Extractor, Tokenizer and Data\n",
        "\n",
        "The ASR pipeline can be de-composed into three stages:\n",
        "1. A feature extractor which pre-processes the raw audio-inputs\n",
        "2. The model which performs the sequence-to-sequence mapping\n",
        "3. A tokenizer which post-processes the model outputs to text format\n",
        "\n",
        "In 🤗 Transformers, the Whisper model has an associated feature extractor and tokenizer,\n",
        "called [WhisperFeatureExtractor](https://huggingface.co/docs/transformers/main/model_doc/whisper#transformers.WhisperFeatureExtractor)\n",
        "and [WhisperTokenizer](https://huggingface.co/docs/transformers/main/model_doc/whisper#transformers.WhisperTokenizer)\n",
        "respectively."
      ],
      "id": "2d63b2d2-f68a-4d74-b7f1-5127f6d16605"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "bc77d7bb-f9e2-47f5-b663-30f7a4321ce5"
      },
      "outputs": [],
      "source": [
        "from transformers import WhisperFeatureExtractor\n",
        "\n",
        "feature_extractor = WhisperFeatureExtractor.from_pretrained(model_name_or_path)"
      ],
      "id": "bc77d7bb-f9e2-47f5-b663-30f7a4321ce5"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "c7b07f9b-ae0e-4f89-98f0-0c50d432eab6"
      },
      "outputs": [],
      "source": [
        "from transformers import WhisperTokenizer\n",
        "\n",
        "tokenizer = WhisperTokenizer.from_pretrained(model_name_or_path, language=language, task=task)"
      ],
      "id": "c7b07f9b-ae0e-4f89-98f0-0c50d432eab6"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gIaGxWbXkcrC"
      },
      "source": [
        "To simplify using the feature extractor and tokenizer, we can _wrap_ both into a single `WhisperProcessor` class. This processor object can be used on the audio inputs and model predictions as required.\n",
        "In doing so, we only need to keep track of two objects during training:\n",
        "the `processor` and the `model`:"
      ],
      "id": "gIaGxWbXkcrC"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "77d9f0c5-8607-4642-a8ac-c3ab2e223ea6"
      },
      "outputs": [],
      "source": [
        "from transformers import WhisperProcessor\n",
        "\n",
        "processor = WhisperProcessor.from_pretrained(model_name_or_path, language=language, task=task)"
      ],
      "id": "77d9f0c5-8607-4642-a8ac-c3ab2e223ea6"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "381acd09-0b0f-4d04-9eb3-f028ac0e5f2c"
      },
      "source": [
        "### Prepare Data\n",
        "\n",
        "Let's print the first example of the Common Voice dataset to see\n",
        "what form the data is in:"
      ],
      "id": "381acd09-0b0f-4d04-9eb3-f028ac0e5f2c"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6e6b0ec5-0c94-4e2c-ae24-c791be1b2255",
        "outputId": "e12b29d7-93cb-4a56-ad97-323544c33495"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'audio': {'path': '/root/.cache/huggingface/datasets/downloads/extracted/a300851d5f8f83446e0518577a5c0e445b9879874d9eb04a87faf332819dd463/common_voice_id_25361388.mp3', 'array': array([ 0.00000000e+00, -7.95807864e-13, -1.39266376e-12, ...,\n",
            "        1.01578926e-05,  2.26661632e-05,  1.37273510e-05]), 'sampling_rate': 48000}, 'sentence': 'Saya mendengarkan cerita membosankan dari teman saya.'}\n"
          ]
        }
      ],
      "source": [
        "print(common_voice[\"train\"][0])"
      ],
      "id": "6e6b0ec5-0c94-4e2c-ae24-c791be1b2255"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5a679f05-063d-41b3-9b58-4fc9c6ccf4fd"
      },
      "source": [
        "Since\n",
        "our input audio is sampled at 48kHz, we need to _downsample_ it to\n",
        "16kHz prior to passing it to the Whisper feature extractor, 16kHz being the sampling rate expected by the Whisper model.\n",
        "\n",
        "We'll set the audio inputs to the correct sampling rate using dataset's\n",
        "[`cast_column`](https://huggingface.co/docs/datasets/package_reference/main_classes.html?highlight=cast_column#datasets.DatasetDict.cast_column)\n",
        "method. This operation does not change the audio in-place,\n",
        "but rather signals to `datasets` to resample audio samples _on the fly_ the\n",
        "first time that they are loaded:"
      ],
      "id": "5a679f05-063d-41b3-9b58-4fc9c6ccf4fd"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "f12e2e57-156f-417b-8cfb-69221cc198e8"
      },
      "outputs": [],
      "source": [
        "from datasets import Audio\n",
        "\n",
        "common_voice = common_voice.cast_column(\"audio\", Audio(sampling_rate=16000))"
      ],
      "id": "f12e2e57-156f-417b-8cfb-69221cc198e8"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00382a3e-abec-4cdd-a54c-d1aaa3ea4707"
      },
      "source": [
        "Re-loading the first audio sample in the Common Voice dataset will resample\n",
        "it to the desired sampling rate:"
      ],
      "id": "00382a3e-abec-4cdd-a54c-d1aaa3ea4707"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "87122d71-289a-466a-afcf-fa354b18946b",
        "outputId": "4c36971b-b90d-4b51-b218-87fd5dadce1f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'audio': {'path': '/root/.cache/huggingface/datasets/downloads/extracted/a300851d5f8f83446e0518577a5c0e445b9879874d9eb04a87faf332819dd463/common_voice_id_25361388.mp3', 'array': array([-2.32830644e-09,  1.86264515e-09, -9.31322575e-10, ...,\n",
            "       -2.64349492e-05, -7.05649245e-06,  2.22347239e-06]), 'sampling_rate': 16000}, 'sentence': 'Saya mendengarkan cerita membosankan dari teman saya.'}\n"
          ]
        }
      ],
      "source": [
        "print(common_voice[\"train\"][0])"
      ],
      "id": "87122d71-289a-466a-afcf-fa354b18946b"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91edc72d-08f8-4f01-899d-74e65ce441fc"
      },
      "source": [
        "Now we can write a function to prepare our data ready for the model:\n",
        "1. We load and resample the audio data by calling `batch[\"audio\"]`. As explained above, 🤗 Datasets performs any necessary resampling operations on the fly.\n",
        "2. We use the feature extractor to compute the log-Mel spectrogram input features from our 1-dimensional audio array.\n",
        "3. We encode the transcriptions to label ids through the use of the tokenizer."
      ],
      "id": "91edc72d-08f8-4f01-899d-74e65ce441fc"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "6525c478-8962-4394-a1c4-103c54cce170"
      },
      "outputs": [],
      "source": [
        "def prepare_dataset(batch):\n",
        "    # load and resample audio data from 48 to 16kHz\n",
        "    audio = batch[\"audio\"]\n",
        "\n",
        "    # compute log-Mel input features from input audio array\n",
        "    batch[\"input_features\"] = feature_extractor(audio[\"array\"], sampling_rate=audio[\"sampling_rate\"]).input_features[0]\n",
        "\n",
        "    # encode target text to label ids\n",
        "    batch[\"labels\"] = tokenizer(batch[\"sentence\"]).input_ids\n",
        "    return batch"
      ],
      "id": "6525c478-8962-4394-a1c4-103c54cce170"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "70b319fb-2439-4ef6-a70d-a47bf41c4a13"
      },
      "source": [
        "We can apply the data preparation function to all of our training examples using dataset's `.map` method. The argument `num_proc` specifies how many CPU cores to use. Setting `num_proc` > 1 will enable multiprocessing. If the `.map` method hangs with multiprocessing, set `num_proc=1` and process the dataset sequentially.\n",
        "\n",
        "Make yourself some tea 🍵, depending on dataset size, this might take 20-30 minutes ⏰"
      ],
      "id": "70b319fb-2439-4ef6-a70d-a47bf41c4a13"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7b73ab39-ffaf-4b9e-86e5-782963c6134b",
        "outputId": "576ab2fc-bc41-42b3-e04d-882ec2c53e34"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/mozilla-foundation___common_voice_13_0/id/13.0.0/22809012aac1fc9803eaffc44122e4149043748e93933935d5ea19898587e4d7/cache-8591de077908b324_*_of_00008.arrow\n",
            "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/mozilla-foundation___common_voice_13_0/id/13.0.0/22809012aac1fc9803eaffc44122e4149043748e93933935d5ea19898587e4d7/cache-a2489f59c099ea22_*_of_00008.arrow\n"
          ]
        }
      ],
      "source": [
        "common_voice = common_voice.map(prepare_dataset, remove_columns=common_voice.column_names[\"train\"], num_proc=8)"
      ],
      "id": "7b73ab39-ffaf-4b9e-86e5-782963c6134b"
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4be572c",
        "outputId": "6dfc78ed-9bfa-441c-8359-6b59dc4ba853"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['input_features', 'labels'],\n",
              "    num_rows: 8333\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "common_voice[\"train\"]"
      ],
      "id": "c4be572c"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "263a5a58-0239-4a25-b0df-c625fc9c5810"
      },
      "source": [
        "## Training and Evaluation\n",
        "\n",
        "Now that we've prepared our data, we're ready to dive into the training pipeline.\n",
        "The [🤗 Trainer](https://huggingface.co/transformers/master/main_classes/trainer.html?highlight=trainer)\n",
        "will do much of the heavy lifting for us. All we have to do is:\n",
        "\n",
        "- Define a data collator: the data collator takes our pre-processed data and prepares PyTorch tensors ready for the model.\n",
        "\n",
        "- Evaluation metrics: during evaluation, we want to evaluate the model using the [word error rate (WER)](https://huggingface.co/metrics/wer) metric.\n",
        "\n",
        "- Load a pre-trained checkpoint: we need to load a pre-trained checkpoint and configure it correctly for training.\n",
        "\n",
        "- Define the training configuration: this will be used by the 🤗 Trainer to define the training schedule.\n",
        "\n",
        "Once we've fine-tuned the model, we will evaluate it on the test data to verify that we have correctly trained it\n",
        "to transcribe speech in Hindi."
      ],
      "id": "263a5a58-0239-4a25-b0df-c625fc9c5810"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8d230e6d-624c-400a-bbf5-fa660881df25"
      },
      "source": [
        "### Define a Data Collator\n",
        "\n",
        "The data collator for a sequence-to-sequence speech model is unique in the sense that it\n",
        "treats the `input_features` and `labels` independently: the  `input_features` must be\n",
        "handled by the feature extractor and the `labels` by the tokenizer.\n",
        "\n",
        "The `input_features` are already padded to 30s and converted to a log-Mel spectrogram\n",
        "of fixed dimension by action of the feature extractor, so all we have to do is convert the `input_features`\n",
        "to batched PyTorch tensors. We do this using the feature extractor's `.pad` method with `return_tensors=pt`.\n",
        "\n",
        "The `labels` on the other hand are un-padded. We first pad the sequences\n",
        "to the maximum length in the batch using the tokenizer's `.pad` method. The padding tokens\n",
        "are then replaced by `-100` so that these tokens are **not** taken into account when\n",
        "computing the loss. We then cut the BOS token from the start of the label sequence as we\n",
        "append it later during training.\n",
        "\n",
        "We can leverage the `WhisperProcessor` we defined earlier to perform both the\n",
        "feature extractor and the tokenizer operations:"
      ],
      "id": "8d230e6d-624c-400a-bbf5-fa660881df25"
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "8326221e-ec13-4731-bb4e-51e5fc1486c5"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "from dataclasses import dataclass\n",
        "from typing import Any, Dict, List, Union\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class DataCollatorSpeechSeq2SeqWithPadding:\n",
        "    processor: Any\n",
        "\n",
        "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
        "        # split inputs and labels since they have to be of different lengths and need different padding methods\n",
        "        # first treat the audio inputs by simply returning torch tensors\n",
        "        input_features = [{\"input_features\": feature[\"input_features\"]} for feature in features]\n",
        "        batch = self.processor.feature_extractor.pad(input_features, return_tensors=\"pt\")\n",
        "\n",
        "        # get the tokenized label sequences\n",
        "        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n",
        "        # pad the labels to max length\n",
        "        labels_batch = self.processor.tokenizer.pad(label_features, return_tensors=\"pt\")\n",
        "\n",
        "        # replace padding with -100 to ignore loss correctly\n",
        "        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n",
        "\n",
        "        # if bos token is appended in previous tokenization step,\n",
        "        # cut bos token here as it's append later anyways\n",
        "        if (labels[:, 0] == self.processor.tokenizer.bos_token_id).all().cpu().item():\n",
        "            labels = labels[:, 1:]\n",
        "\n",
        "        batch[\"labels\"] = labels\n",
        "\n",
        "        return batch"
      ],
      "id": "8326221e-ec13-4731-bb4e-51e5fc1486c5"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3cae7dbf-8a50-456e-a3a8-7fd005390f86"
      },
      "source": [
        "Let's initialise the data collator we've just defined:"
      ],
      "id": "3cae7dbf-8a50-456e-a3a8-7fd005390f86"
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "fc834702-c0d3-4a96-b101-7b87be32bf42"
      },
      "outputs": [],
      "source": [
        "data_collator = DataCollatorSpeechSeq2SeqWithPadding(processor=processor)"
      ],
      "id": "fc834702-c0d3-4a96-b101-7b87be32bf42"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d62bb2ab-750a-45e7-82e9-61d6f4805698"
      },
      "source": [
        "### Evaluation Metrics"
      ],
      "id": "d62bb2ab-750a-45e7-82e9-61d6f4805698"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "66fee1a7-a44c-461e-b047-c3917221572e"
      },
      "source": [
        "We'll use the word error rate (WER) metric, the 'de-facto' metric for assessing\n",
        "ASR systems. For more information, refer to the WER [docs](https://huggingface.co/metrics/wer). We'll load the WER metric from 🤗 Evaluate:"
      ],
      "id": "66fee1a7-a44c-461e-b047-c3917221572e"
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "b22b4011-f31f-4b57-b684-c52332f92890"
      },
      "outputs": [],
      "source": [
        "import evaluate\n",
        "\n",
        "metric = evaluate.load(\"wer\")"
      ],
      "id": "b22b4011-f31f-4b57-b684-c52332f92890"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "daf2a825-6d9f-4a23-b145-c37c0039075b"
      },
      "source": [
        "### Load a Pre-Trained Checkpoint"
      ],
      "id": "daf2a825-6d9f-4a23-b145-c37c0039075b"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "437a97fa-4864-476b-8abc-f28b8166cfa5"
      },
      "source": [
        "Now let's load the pre-trained Whisper checkpoint. Again, this\n",
        "is trivial through use of 🤗 Transformers!\n",
        "\n",
        "To reduce our models memory footprint, we load the model in 8bit, this means we quantize the model to use 1/4th precision (when comapared to float32) with minimal loss to performance. To read more about how this works, head over [here](https://huggingface.co/blog/hf-bitsandbytes-integration)."
      ],
      "id": "437a97fa-4864-476b-8abc-f28b8166cfa5"
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "5a10cc4b-07ec-4ebd-ac1d-7c601023594f"
      },
      "outputs": [],
      "source": [
        "from transformers import WhisperForConditionalGeneration\n",
        "\n",
        "model = WhisperForConditionalGeneration.from_pretrained(model_name_or_path, load_in_8bit=True, device_map=\"auto\")"
      ],
      "id": "5a10cc4b-07ec-4ebd-ac1d-7c601023594f"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bR-_yaEOPsfQ"
      },
      "source": [
        "### Post-processing on the model\n",
        "\n",
        "Finally, we need to apply some post-processing steps on the 8-bit model to enable training. We do so by first freezing all the model layers, and then cast the layer-norm and the output layer in `float32` for training and model stability."
      ],
      "id": "bR-_yaEOPsfQ"
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "Cl_ZQualPt9R"
      },
      "outputs": [],
      "source": [
        "from peft import prepare_model_for_int8_training\n",
        "\n",
        "model = prepare_model_for_int8_training(model, output_embedding_layer_name=\"proj_out\")"
      ],
      "id": "Cl_ZQualPt9R"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since the Whisper model uses Convolutional layers in the Encoder, checkpointing disables grad computation to avoid this we specifically need to make the inputs trainable."
      ],
      "metadata": {
        "id": "p0Ja2e__OX02"
      },
      "id": "p0Ja2e__OX02"
    },
    {
      "cell_type": "code",
      "source": [
        "def make_inputs_require_grad(module, input, output):\n",
        "    output.requires_grad_(True)\n",
        "\n",
        "model.model.encoder.conv1.register_forward_hook(make_inputs_require_grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bmpeiajSOWCy",
        "outputId": "d4e16b3e-1fe3-4ac7-fb65-7dabef796f90"
      },
      "id": "bmpeiajSOWCy",
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.utils.hooks.RemovableHandle at 0x7f18eb759a20>"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vjl4j4RJPmPR"
      },
      "source": [
        "### Apply Low-rank adapters (LoRA) to the model\n",
        "\n",
        "Here comes the magic with `peft`! Let's load a `PeftModel` and specify that we are going to use low-rank adapters (LoRA) using `get_peft_model` utility function from `peft`."
      ],
      "id": "Vjl4j4RJPmPR"
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DQtpDPRHPyOL",
        "outputId": "c58c8fb8-a034-4e25-bc12-2907f2ab0a59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable params: 15728640 || all params: 1559033600 || trainable%: 1.0088711365810203\n"
          ]
        }
      ],
      "source": [
        "from peft import LoraConfig, PeftModel, LoraModel, LoraConfig, get_peft_model\n",
        "\n",
        "config = LoraConfig(r=32, lora_alpha=64, target_modules=[\"q_proj\", \"v_proj\"], lora_dropout=0.05, bias=\"none\")\n",
        "\n",
        "model = get_peft_model(model, config)\n",
        "model.print_trainable_parameters()"
      ],
      "id": "DQtpDPRHPyOL"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3906d436"
      },
      "source": [
        "We are ONLY using **1%** of the total trainable parameters, thereby performing **Parameter-Efficient Fine-Tuning**"
      ],
      "id": "3906d436"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2178dea4-80ca-47b6-b6ea-ba1915c90c06"
      },
      "source": [
        "### Define the Training Configuration"
      ],
      "id": "2178dea4-80ca-47b6-b6ea-ba1915c90c06"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c21af1e9-0188-4134-ac82-defc7bdcc436"
      },
      "source": [
        "In the final step, we define all the parameters related to training. For more detail on the training arguments, refer to the Seq2SeqTrainingArguments [docs](https://huggingface.co/docs/transformers/main_classes/trainer#transformers.Seq2SeqTrainingArguments)."
      ],
      "id": "c21af1e9-0188-4134-ac82-defc7bdcc436"
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "0ae3e9af-97b7-4aa0-ae85-20b23b5bcb3a"
      },
      "outputs": [],
      "source": [
        "from transformers import Seq2SeqTrainingArguments\n",
        "\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=\"mfaiq2307/whisper-large-v2-5000steps-peft\",  # change to a repo name of your choice\n",
        "    per_device_train_batch_size=8,\n",
        "    gradient_accumulation_steps=1,  # increase by 2x for every 2x decrease in batch size\n",
        "    learning_rate=1e-3,\n",
        "    warmup_steps=50,\n",
        "    num_train_epochs=10,\n",
        "    evaluation_strategy=\"steps\",\n",
        "    fp16=True,\n",
        "    per_device_eval_batch_size=8,\n",
        "    generation_max_length=128,\n",
        "    logging_steps=10000,\n",
        "    max_steps=5000, # only for testing purposes, remove this from your final run :)\n",
        "    remove_unused_columns=False,  # required as the PeftModel forward doesn't have the signature of the wrapped model's forward\n",
        "    label_names=[\"labels\"],  # same reason as above\n",
        ")"
      ],
      "id": "0ae3e9af-97b7-4aa0-ae85-20b23b5bcb3a"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3a944d8-3112-4552-82a0-be25988b3857"
      },
      "source": [
        "Fine-tuning a model with PEFT comes with a few caveats.\n",
        "\n",
        "1. We need to explicitly set `remove_unused_columns=False` and `label_names=[\"labels\"]` as the PeftModel's forward doesn't inherit the signature of the base model's forward.\n",
        "\n",
        "2. Since INT8 training requires autocasting, we cannot use the native `predict_with_generate` call in Trainer as it doesn't automatically cast.\n",
        "\n",
        "3. Similarly, since we cannot autocast, we cannot pass the `compute_metrics` to `Seq2SeqTrainer` so we'll comment it out whilst instantiating the Trainer."
      ],
      "id": "b3a944d8-3112-4552-82a0-be25988b3857"
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "d546d7fe-0543-479a-b708-2ebabec19493"
      },
      "outputs": [],
      "source": [
        "from transformers import Seq2SeqTrainer, TrainerCallback, TrainingArguments, TrainerState, TrainerControl\n",
        "from transformers.trainer_utils import PREFIX_CHECKPOINT_DIR\n",
        "\n",
        "# This callback helps to save only the adapter weights and remove the base model weights.\n",
        "class SavePeftModelCallback(TrainerCallback):\n",
        "    def on_save(\n",
        "        self,\n",
        "        args: TrainingArguments,\n",
        "        state: TrainerState,\n",
        "        control: TrainerControl,\n",
        "        **kwargs,\n",
        "    ):\n",
        "        checkpoint_folder = os.path.join(args.output_dir, f\"{PREFIX_CHECKPOINT_DIR}-{state.global_step}\")\n",
        "\n",
        "        peft_model_path = os.path.join(checkpoint_folder, \"adapter_model\")\n",
        "        kwargs[\"model\"].save_pretrained(peft_model_path)\n",
        "\n",
        "        pytorch_model_path = os.path.join(checkpoint_folder, \"pytorch_model.bin\")\n",
        "        if os.path.exists(pytorch_model_path):\n",
        "            os.remove(pytorch_model_path)\n",
        "        return control\n",
        "\n",
        "\n",
        "trainer = Seq2SeqTrainer(\n",
        "    args=training_args,\n",
        "    model=model,\n",
        "    train_dataset=common_voice[\"train\"],\n",
        "    eval_dataset=common_voice[\"test\"],\n",
        "    data_collator=data_collator,\n",
        "    # compute_metrics=compute_metrics,\n",
        "    tokenizer=processor.feature_extractor,\n",
        "    #callbacks=[SavePeftModelCallback],\n",
        ")\n",
        "model.config.use_cache = False  # silence the warnings. Please re-enable for inference!"
      ],
      "id": "d546d7fe-0543-479a-b708-2ebabec19493"
    },
    {
      "cell_type": "code",
      "source": [
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\""
      ],
      "metadata": {
        "id": "ZUgefb1N7oNK"
      },
      "id": "ZUgefb1N7oNK",
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb\n",
        "import wandb\n",
        "wandb.init()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "970d01f3bed44e60952bc19c20b1bc7f",
            "67cf484e8b6c41d98e7b4a78cd98252a",
            "3807811ce9294abbbba112fd158f3267",
            "737ddad117c14279aaf2e390bb860ddd",
            "ed362d19820e44959ec2571d14645dda",
            "8e724843ca5c4a4b86a6236e0d7034e1",
            "1c4a951161e846e5b924ff8357f9e660",
            "4a5ee5bcf0a742e8aba7a0253c470900"
          ]
        },
        "id": "OTcTqoK57ax-",
        "outputId": "657ac1ab-a04a-4908-b07e-9452b4247701"
      },
      "id": "OTcTqoK57ax-",
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting wandb\n",
            "  Downloading wandb-0.15.4-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m34.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Collecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.26.0-py2.py3-none-any.whl (209 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.4/209.4 kB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0)\n",
            "Collecting pathtools\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.27.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n",
            "Collecting setproctitle\n",
            "  Downloading setproctitle-1.3.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.3)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Collecting GitPython!=3.1.29,>=1.0.0\n",
            "  Downloading GitPython-3.1.31-py3-none-any.whl (184 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 kB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2022.12.7)\n",
            "Collecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Building wheels for collected packages: pathtools\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8807 sha256=ac070c1f24513b80645dcb589910ebd3e58ec4b6f059a2f257debe9fb4898352\n",
            "  Stored in directory: /root/.cache/pip/wheels/e7/f3/22/152153d6eb222ee7a56ff8617d80ee5207207a8c00a7aab794\n",
            "Successfully built pathtools\n",
            "Installing collected packages: pathtools, smmap, setproctitle, sentry-sdk, docker-pycreds, gitdb, GitPython, wandb\n",
            "Successfully installed GitPython-3.1.31 docker-pycreds-0.4.0 gitdb-4.0.10 pathtools-0.1.2 sentry-sdk-1.26.0 setproctitle-1.3.2 smmap-5.0.0 wandb-0.15.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01666968036667337, max=1.0)…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "970d01f3bed44e60952bc19c20b1bc7f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.15.4"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230624_150411-eb0aqzht</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/skripsifaiq/uncategorized/runs/eb0aqzht' target=\"_blank\">sparkling-water-39</a></strong> to <a href='https://wandb.ai/skripsifaiq/uncategorized' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/skripsifaiq/uncategorized' target=\"_blank\">https://wandb.ai/skripsifaiq/uncategorized</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/skripsifaiq/uncategorized/runs/eb0aqzht' target=\"_blank\">https://wandb.ai/skripsifaiq/uncategorized/runs/eb0aqzht</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/skripsifaiq/uncategorized/runs/eb0aqzht?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7f18eb740550>"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        },
        "id": "ee8b7b8e-1c9a-4d77-9137-1778a629e6de",
        "outputId": "27da62e7-d48b-4a84-83aa-3b3960deeb3b"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/autograd/_functions.py:321: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='5000' max='5000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [5000/5000 7:04:01, Epoch 4/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/autograd/_functions.py:321: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/autograd/_functions.py:321: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/autograd/_functions.py:321: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/autograd/_functions.py:321: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/autograd/_functions.py:321: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/autograd/_functions.py:321: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/autograd/_functions.py:321: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/autograd/_functions.py:321: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/autograd/_functions.py:321: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        }
      ],
      "source": [
        "with torch.cuda.amp.autocast():\n",
        "    trainer.train()"
      ],
      "id": "ee8b7b8e-1c9a-4d77-9137-1778a629e6de"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that our model is fine-tuned, we can push the model on to Hugging Face Hub, this will later help us directly infer the model from the model repo."
      ],
      "metadata": {
        "id": "8iqXhUiuBQCs"
      },
      "id": "8iqXhUiuBQCs"
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117,
          "referenced_widgets": [
            "df3b5f612bb349fdaa381386132f149e",
            "69d829ca638d43c8b334408d7fac0d4b",
            "e38d511caf774545a495c1a80a45065b",
            "5cf1f3e9b1604f638b1731933c9fcb97",
            "699568f1c0564859891f44f8b968ab8f",
            "014b6e3e23cb4d5c8d97e003c0fc013e",
            "9d8585fbbcd94f37bbb86e9061be5aa7",
            "5534196a013e4aca87ab721dd95b0870",
            "faafced32b664208bd46e3440492ac16",
            "08d1117eb6014938ba813f9b0d2b04cb",
            "f9fedb2dbfde4e6988d97e06f9435380",
            "a8a6c679fb3a40cb930d395814a66510",
            "5200c24f587e47338fc4602519247783",
            "93c8037eecf1444f821eb320e85ae402",
            "eff86d2e2b744dbba784bd509616d665",
            "cdc1713be8a74774b8bdf7a9cd47e249",
            "52115da094304c75b43a471097d6c33f",
            "7dca32b39e6c4e71a44ca01ba6272611",
            "8fbf2e5366e5499cbfbc8751411ad438",
            "9aa8d9c0388c414fb3e1fb57b6d1f298",
            "26302f28651f47efa440bdc5d455df37",
            "d8f06788ffe44d25bfa8522ec82b1c13"
          ]
        },
        "id": "0576aa2a",
        "outputId": "282dc696-a754-4ce6-c42c-92dd8c781653"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Upload 1 LFS files:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "df3b5f612bb349fdaa381386132f149e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "adapter_model.bin:   0%|          | 0.00/63.1M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a8a6c679fb3a40cb930d395814a66510"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CommitInfo(commit_url='https://huggingface.co/mfaiq2307/whisper-large-v2-5000steps-peft/commit/5ffee3e2888949e7f46e3bf3d937ac320f977d32', commit_message='Upload model', commit_description='', oid='5ffee3e2888949e7f46e3bf3d937ac320f977d32', pr_url=None, pr_revision=None, pr_num=None)"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ],
      "source": [
        "peft_model_id = \"mfaiq2307/whisper-large-v2-5000steps-peft\"\n",
        "model.push_to_hub(peft_model_id)"
      ],
      "id": "0576aa2a"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SlyyOGnPgi_I"
      },
      "source": [
        "# Evaluation and Inference"
      ],
      "id": "SlyyOGnPgi_I"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kzfg2qoXgrhg"
      },
      "source": [
        "On to the fun part, we've successfully fine-tuned our model. Now let's put it to test and calculate the WER on the `test` set.\n",
        "\n",
        "As with training, we do have a few caveats to pay attention to:\n",
        "1. Since we cannot use `predict_with_generate` function, we will hand roll our own eval loop with `torch.cuda.amp.autocast()` you can check it out below.\n",
        "2. Since the base model is frozen, PEFT model sometimes fails to recognise the language while decoding. To fix that, we force the starting tokens to mention the language we are transcribing. This is done via `forced_decoder_ids = processor.get_decoder_prompt_ids(language=\"Marathi\", task=\"transcribe\")` and passing that too the `model.generate` call.\n",
        "\n",
        "That's it, let's get transcribing! 🔥\n"
      ],
      "id": "Kzfg2qoXgrhg"
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "273a996c"
      },
      "outputs": [],
      "source": [
        "from peft import PeftModel, PeftConfig\n",
        "from transformers import WhisperForConditionalGeneration, Seq2SeqTrainer\n",
        "\n",
        "peft_model_id = \"mfaiq2307/whisper-large-v2-5000steps-peft\" # Use the same model ID as before.\n",
        "peft_config = PeftConfig.from_pretrained(peft_model_id)\n",
        "model = WhisperForConditionalGeneration.from_pretrained(\n",
        "    peft_config.base_model_name_or_path, load_in_8bit=True, device_map=\"auto\"\n",
        ")\n",
        "model = PeftModel.from_pretrained(model, peft_model_id)\n",
        "model.config.use_cache = True"
      ],
      "id": "273a996c"
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "401ceaa6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab0425a2-e960-4b25-db3f-3738e605169b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 457/457 [1:04:38<00:00,  8.49s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "wer=13.055299539170505 and normalized_wer=8.620768422495317\n",
            "{'eval/wer': 13.055299539170505, 'eval/normalized_wer': 8.620768422495317}\n"
          ]
        }
      ],
      "source": [
        "import gc\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers.models.whisper.english_normalizer import BasicTextNormalizer\n",
        "\n",
        "eval_dataloader = DataLoader(common_voice[\"test\"], batch_size=8, collate_fn=data_collator)\n",
        "forced_decoder_ids = processor.get_decoder_prompt_ids(language=language, task=task)\n",
        "normalizer = BasicTextNormalizer()\n",
        "\n",
        "predictions = []\n",
        "references = []\n",
        "normalized_predictions = []\n",
        "normalized_references = []\n",
        "\n",
        "model.eval()\n",
        "for step, batch in enumerate(tqdm(eval_dataloader)):\n",
        "    with torch.cuda.amp.autocast():\n",
        "        with torch.no_grad():\n",
        "            generated_tokens = (\n",
        "                model.generate(\n",
        "                    input_features=batch[\"input_features\"].to(\"cuda\"),\n",
        "                    forced_decoder_ids=forced_decoder_ids,\n",
        "                    max_new_tokens=255,\n",
        "                )\n",
        "                .cpu()\n",
        "                .numpy()\n",
        "            )\n",
        "            labels = batch[\"labels\"].cpu().numpy()\n",
        "            labels = np.where(labels != -100, labels, processor.tokenizer.pad_token_id)\n",
        "            decoded_preds = processor.tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n",
        "            decoded_labels = processor.tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "            predictions.extend(decoded_preds)\n",
        "            references.extend(decoded_labels)\n",
        "            normalized_predictions.extend([normalizer(pred).strip() for pred in decoded_preds])\n",
        "            normalized_references.extend([normalizer(label).strip() for label in decoded_labels])\n",
        "        del generated_tokens, labels, batch\n",
        "    gc.collect()\n",
        "wer = 100 * metric.compute(predictions=predictions, references=references)\n",
        "normalized_wer = 100 * metric.compute(predictions=normalized_predictions, references=normalized_references)\n",
        "eval_metrics = {\"eval/wer\": wer, \"eval/normalized_wer\": normalized_wer}\n",
        "\n",
        "print(f\"{wer=} and {normalized_wer=}\")\n",
        "print(eval_metrics)"
      ],
      "id": "401ceaa6"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fin!\n",
        "\n",
        "If you made it all the way till the end then pat yourself on the back. Looking back, we learned how to train *any* Whisper checkpoint faster, cheaper and with negligible loss in WER.\n",
        "\n",
        "With PEFT, you can also go beyond Speech recognition and apply the same set of techniques to other pretrained models as well. Come check it out here: https://github.com/huggingface/peft 🤗\n",
        "\n",
        "Don't forget to tweet your results and tag us! [@huggingface](https://twitter.com/huggingface) and [@reach_vb](https://twitter.com/reach_vb) ❤️"
      ],
      "metadata": {
        "id": "j3XF0PzsCV0v"
      },
      "id": "j3XF0PzsCV0v"
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "816d8f0ad9e24a319ed2bf9d631fbdbb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_22fd3006e67447d08c3a0357cce6a097",
              "IPY_MODEL_dd4c9944d49c466cb429a60f1637b415",
              "IPY_MODEL_956683b15f534dac87e967ea4d2e150e",
              "IPY_MODEL_56c15eca011b40bda614f216d9d39178"
            ],
            "layout": "IPY_MODEL_5e3dd987a32f40fba73751e0546e9cb2"
          }
        },
        "4d7b760327d14326acc69f51baa19856": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9adfdcad8feb4f4daddc0ff0a8ac5934",
            "placeholder": "​",
            "style": "IPY_MODEL_3f1f3b36d6c74fd58e0f844c38a01ca1",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "e424996b5fc34fd5809fddd0250492e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_21bc8e541e22444c86f98948fcbfa001",
            "placeholder": "​",
            "style": "IPY_MODEL_7ed3852664ea4964b189bc1ba424ad3a",
            "value": ""
          }
        },
        "9e8c038169cf47288a0da9f50e1d1b48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_1741456fec04410192cdc333ea980158",
            "style": "IPY_MODEL_fb6234984b10494ca95c5f2764dcec12",
            "value": true
          }
        },
        "47d97646ec8e404facaf49e8e06852e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_7b9fdc420cb9450e9db0e787b532fae4",
            "style": "IPY_MODEL_b4c4867224f94fa0bf9f6a8f1a75dc6a",
            "tooltip": ""
          }
        },
        "3c2f06b6024045dcaded354b23c5cf02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6045c0dbdd2c45cea65e1227cbb00039",
            "placeholder": "​",
            "style": "IPY_MODEL_33c1013250dd4ea3b2af3663eba6ae75",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "5e3dd987a32f40fba73751e0546e9cb2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "9adfdcad8feb4f4daddc0ff0a8ac5934": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f1f3b36d6c74fd58e0f844c38a01ca1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "21bc8e541e22444c86f98948fcbfa001": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ed3852664ea4964b189bc1ba424ad3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1741456fec04410192cdc333ea980158": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb6234984b10494ca95c5f2764dcec12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7b9fdc420cb9450e9db0e787b532fae4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b4c4867224f94fa0bf9f6a8f1a75dc6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "6045c0dbdd2c45cea65e1227cbb00039": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33c1013250dd4ea3b2af3663eba6ae75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "292f6f3b4d0f4f249777e14d6ceea99d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5fcc534556fb4b158e7ac12c5d1b7112",
            "placeholder": "​",
            "style": "IPY_MODEL_94d35dc19f6441d4978235901c76cadd",
            "value": "Connecting..."
          }
        },
        "5fcc534556fb4b158e7ac12c5d1b7112": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "94d35dc19f6441d4978235901c76cadd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "22fd3006e67447d08c3a0357cce6a097": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e6147ce00db94d20b0a422cbc53db128",
            "placeholder": "​",
            "style": "IPY_MODEL_de58f41f178b4eabbf65210503163cc4",
            "value": "Token is valid (permission: write)."
          }
        },
        "dd4c9944d49c466cb429a60f1637b415": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e58dd3f4b13a47eda8f85d35b362e299",
            "placeholder": "​",
            "style": "IPY_MODEL_9328578d5e534286ac61a3ae53ea3400",
            "value": "Your token has been saved in your configured git credential helpers (store)."
          }
        },
        "956683b15f534dac87e967ea4d2e150e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_15865653f578497ea05cf0ddeb2f79ef",
            "placeholder": "​",
            "style": "IPY_MODEL_a766499eb4eb4e60903acafc2251b159",
            "value": "Your token has been saved to /root/.cache/huggingface/token"
          }
        },
        "56c15eca011b40bda614f216d9d39178": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ababb664997946bfa11026bc59a3c815",
            "placeholder": "​",
            "style": "IPY_MODEL_e4410ca791c8427f97b5414acb150d08",
            "value": "Login successful"
          }
        },
        "e6147ce00db94d20b0a422cbc53db128": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de58f41f178b4eabbf65210503163cc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e58dd3f4b13a47eda8f85d35b362e299": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9328578d5e534286ac61a3ae53ea3400": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "15865653f578497ea05cf0ddeb2f79ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a766499eb4eb4e60903acafc2251b159": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ababb664997946bfa11026bc59a3c815": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e4410ca791c8427f97b5414acb150d08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "970d01f3bed44e60952bc19c20b1bc7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_67cf484e8b6c41d98e7b4a78cd98252a",
              "IPY_MODEL_3807811ce9294abbbba112fd158f3267"
            ],
            "layout": "IPY_MODEL_737ddad117c14279aaf2e390bb860ddd"
          }
        },
        "67cf484e8b6c41d98e7b4a78cd98252a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ed362d19820e44959ec2571d14645dda",
            "placeholder": "​",
            "style": "IPY_MODEL_8e724843ca5c4a4b86a6236e0d7034e1",
            "value": "Waiting for wandb.init()...\r"
          }
        },
        "3807811ce9294abbbba112fd158f3267": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1c4a951161e846e5b924ff8357f9e660",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4a5ee5bcf0a742e8aba7a0253c470900",
            "value": 1
          }
        },
        "737ddad117c14279aaf2e390bb860ddd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed362d19820e44959ec2571d14645dda": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e724843ca5c4a4b86a6236e0d7034e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1c4a951161e846e5b924ff8357f9e660": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a5ee5bcf0a742e8aba7a0253c470900": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "df3b5f612bb349fdaa381386132f149e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_69d829ca638d43c8b334408d7fac0d4b",
              "IPY_MODEL_e38d511caf774545a495c1a80a45065b",
              "IPY_MODEL_5cf1f3e9b1604f638b1731933c9fcb97"
            ],
            "layout": "IPY_MODEL_699568f1c0564859891f44f8b968ab8f"
          }
        },
        "69d829ca638d43c8b334408d7fac0d4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_014b6e3e23cb4d5c8d97e003c0fc013e",
            "placeholder": "​",
            "style": "IPY_MODEL_9d8585fbbcd94f37bbb86e9061be5aa7",
            "value": "Upload 1 LFS files: 100%"
          }
        },
        "e38d511caf774545a495c1a80a45065b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5534196a013e4aca87ab721dd95b0870",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_faafced32b664208bd46e3440492ac16",
            "value": 1
          }
        },
        "5cf1f3e9b1604f638b1731933c9fcb97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_08d1117eb6014938ba813f9b0d2b04cb",
            "placeholder": "​",
            "style": "IPY_MODEL_f9fedb2dbfde4e6988d97e06f9435380",
            "value": " 1/1 [00:04&lt;00:00,  4.13s/it]"
          }
        },
        "699568f1c0564859891f44f8b968ab8f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "014b6e3e23cb4d5c8d97e003c0fc013e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d8585fbbcd94f37bbb86e9061be5aa7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5534196a013e4aca87ab721dd95b0870": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "faafced32b664208bd46e3440492ac16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "08d1117eb6014938ba813f9b0d2b04cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f9fedb2dbfde4e6988d97e06f9435380": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a8a6c679fb3a40cb930d395814a66510": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5200c24f587e47338fc4602519247783",
              "IPY_MODEL_93c8037eecf1444f821eb320e85ae402",
              "IPY_MODEL_eff86d2e2b744dbba784bd509616d665"
            ],
            "layout": "IPY_MODEL_cdc1713be8a74774b8bdf7a9cd47e249"
          }
        },
        "5200c24f587e47338fc4602519247783": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_52115da094304c75b43a471097d6c33f",
            "placeholder": "​",
            "style": "IPY_MODEL_7dca32b39e6c4e71a44ca01ba6272611",
            "value": "adapter_model.bin: 100%"
          }
        },
        "93c8037eecf1444f821eb320e85ae402": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8fbf2e5366e5499cbfbc8751411ad438",
            "max": 63056269,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9aa8d9c0388c414fb3e1fb57b6d1f298",
            "value": 63056269
          }
        },
        "eff86d2e2b744dbba784bd509616d665": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_26302f28651f47efa440bdc5d455df37",
            "placeholder": "​",
            "style": "IPY_MODEL_d8f06788ffe44d25bfa8522ec82b1c13",
            "value": " 63.1M/63.1M [00:03&lt;00:00, 24.5MB/s]"
          }
        },
        "cdc1713be8a74774b8bdf7a9cd47e249": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52115da094304c75b43a471097d6c33f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7dca32b39e6c4e71a44ca01ba6272611": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8fbf2e5366e5499cbfbc8751411ad438": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9aa8d9c0388c414fb3e1fb57b6d1f298": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "26302f28651f47efa440bdc5d455df37": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8f06788ffe44d25bfa8522ec82b1c13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}